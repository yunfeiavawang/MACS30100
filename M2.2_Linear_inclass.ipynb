{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "46eed391",
   "metadata": {},
   "source": [
    "## Linear methods for regression and classification\n",
    "In this jupyter notebook, we will practice the topics covered in the lectures. Specially, we will do hands-on practice of:\n",
    "- load and prepare data for machine learning model training and testing\n",
    "- train and test linear models (linear regression (lasso/ridge), polynomial regression, and logistic regression)\n",
    "- compare and understand model performance \n",
    "\n",
    "For implementations that have fixed results, we provide running examples for your reference. *You might get slightly different results due to the sklearn version you are using, just leave a comment to indicate your version where you get different results.*<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5acb55f",
   "metadata": {},
   "source": [
    "## Linear Regression and Polynomial Regression\n",
    "In this section, we will explore the diabetes dataset:\n",
    "- https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_diabetes.html#sklearn.datasets.load_diabetes <br>\n",
    "\n",
    "This dataset contains n = 442 diabetes patients' information of ten variables: age, sex, body mass index, average blood pressure, and six blood serum measurements. Each patient has a quantitative value of disease progression one year after baseline.\n",
    "\n",
    "\n",
    "We will fit different regression models to analyze this dataset: \n",
    "The steps include:\n",
    "1. Basic data exploration:\n",
    "    > what does the data look like (#samples, #features) <br>\n",
    "    > the feature matrix and description of each feature <br>\n",
    "    > the target variable <br>\n",
    "    \n",
    "2. Prepare data for model training and testing <br>\n",
    "\n",
    "3. Fit different regression models (linear/lasso/ridge) on the training set and evaluate model performance on the testing set <br>\n",
    "\n",
    "4. Compare and understand model performance through interpreting coefficients.\n",
    "\n",
    "**Note:** please always add comments to explain your observations/findings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eab86d6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6253bf61",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_diabetes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "36fb790a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# there are different ways to load the dataset, please make sure you understand the mechanism\n",
    "# reference: https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_diabetes.html\n",
    "data = load_diabetes(as_frame=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db355e95",
   "metadata": {},
   "source": [
    "### Basic dataset exploration "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "94e585c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((442, 10), (442,))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.data.shape, data.target.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "83f34331",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['age', 'sex', 'bmi', 'bp', 's1', 's2', 's3', 's4', 's5', 's6']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "abcc0287",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>bmi</th>\n",
       "      <th>bp</th>\n",
       "      <th>s1</th>\n",
       "      <th>s2</th>\n",
       "      <th>s3</th>\n",
       "      <th>s4</th>\n",
       "      <th>s5</th>\n",
       "      <th>s6</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.038076</td>\n",
       "      <td>0.050680</td>\n",
       "      <td>0.061696</td>\n",
       "      <td>0.021872</td>\n",
       "      <td>-0.044223</td>\n",
       "      <td>-0.034821</td>\n",
       "      <td>-0.043401</td>\n",
       "      <td>-0.002592</td>\n",
       "      <td>0.019907</td>\n",
       "      <td>-0.017646</td>\n",
       "      <td>151.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.001882</td>\n",
       "      <td>-0.044642</td>\n",
       "      <td>-0.051474</td>\n",
       "      <td>-0.026328</td>\n",
       "      <td>-0.008449</td>\n",
       "      <td>-0.019163</td>\n",
       "      <td>0.074412</td>\n",
       "      <td>-0.039493</td>\n",
       "      <td>-0.068332</td>\n",
       "      <td>-0.092204</td>\n",
       "      <td>75.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.085299</td>\n",
       "      <td>0.050680</td>\n",
       "      <td>0.044451</td>\n",
       "      <td>-0.005670</td>\n",
       "      <td>-0.045599</td>\n",
       "      <td>-0.034194</td>\n",
       "      <td>-0.032356</td>\n",
       "      <td>-0.002592</td>\n",
       "      <td>0.002861</td>\n",
       "      <td>-0.025930</td>\n",
       "      <td>141.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.089063</td>\n",
       "      <td>-0.044642</td>\n",
       "      <td>-0.011595</td>\n",
       "      <td>-0.036656</td>\n",
       "      <td>0.012191</td>\n",
       "      <td>0.024991</td>\n",
       "      <td>-0.036038</td>\n",
       "      <td>0.034309</td>\n",
       "      <td>0.022688</td>\n",
       "      <td>-0.009362</td>\n",
       "      <td>206.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.005383</td>\n",
       "      <td>-0.044642</td>\n",
       "      <td>-0.036385</td>\n",
       "      <td>0.021872</td>\n",
       "      <td>0.003935</td>\n",
       "      <td>0.015596</td>\n",
       "      <td>0.008142</td>\n",
       "      <td>-0.002592</td>\n",
       "      <td>-0.031988</td>\n",
       "      <td>-0.046641</td>\n",
       "      <td>135.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>437</th>\n",
       "      <td>0.041708</td>\n",
       "      <td>0.050680</td>\n",
       "      <td>0.019662</td>\n",
       "      <td>0.059744</td>\n",
       "      <td>-0.005697</td>\n",
       "      <td>-0.002566</td>\n",
       "      <td>-0.028674</td>\n",
       "      <td>-0.002592</td>\n",
       "      <td>0.031193</td>\n",
       "      <td>0.007207</td>\n",
       "      <td>178.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>438</th>\n",
       "      <td>-0.005515</td>\n",
       "      <td>0.050680</td>\n",
       "      <td>-0.015906</td>\n",
       "      <td>-0.067642</td>\n",
       "      <td>0.049341</td>\n",
       "      <td>0.079165</td>\n",
       "      <td>-0.028674</td>\n",
       "      <td>0.034309</td>\n",
       "      <td>-0.018114</td>\n",
       "      <td>0.044485</td>\n",
       "      <td>104.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>439</th>\n",
       "      <td>0.041708</td>\n",
       "      <td>0.050680</td>\n",
       "      <td>-0.015906</td>\n",
       "      <td>0.017293</td>\n",
       "      <td>-0.037344</td>\n",
       "      <td>-0.013840</td>\n",
       "      <td>-0.024993</td>\n",
       "      <td>-0.011080</td>\n",
       "      <td>-0.046883</td>\n",
       "      <td>0.015491</td>\n",
       "      <td>132.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>440</th>\n",
       "      <td>-0.045472</td>\n",
       "      <td>-0.044642</td>\n",
       "      <td>0.039062</td>\n",
       "      <td>0.001215</td>\n",
       "      <td>0.016318</td>\n",
       "      <td>0.015283</td>\n",
       "      <td>-0.028674</td>\n",
       "      <td>0.026560</td>\n",
       "      <td>0.044529</td>\n",
       "      <td>-0.025930</td>\n",
       "      <td>220.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>441</th>\n",
       "      <td>-0.045472</td>\n",
       "      <td>-0.044642</td>\n",
       "      <td>-0.073030</td>\n",
       "      <td>-0.081413</td>\n",
       "      <td>0.083740</td>\n",
       "      <td>0.027809</td>\n",
       "      <td>0.173816</td>\n",
       "      <td>-0.039493</td>\n",
       "      <td>-0.004222</td>\n",
       "      <td>0.003064</td>\n",
       "      <td>57.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>442 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          age       sex       bmi        bp        s1        s2        s3  \\\n",
       "0    0.038076  0.050680  0.061696  0.021872 -0.044223 -0.034821 -0.043401   \n",
       "1   -0.001882 -0.044642 -0.051474 -0.026328 -0.008449 -0.019163  0.074412   \n",
       "2    0.085299  0.050680  0.044451 -0.005670 -0.045599 -0.034194 -0.032356   \n",
       "3   -0.089063 -0.044642 -0.011595 -0.036656  0.012191  0.024991 -0.036038   \n",
       "4    0.005383 -0.044642 -0.036385  0.021872  0.003935  0.015596  0.008142   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "437  0.041708  0.050680  0.019662  0.059744 -0.005697 -0.002566 -0.028674   \n",
       "438 -0.005515  0.050680 -0.015906 -0.067642  0.049341  0.079165 -0.028674   \n",
       "439  0.041708  0.050680 -0.015906  0.017293 -0.037344 -0.013840 -0.024993   \n",
       "440 -0.045472 -0.044642  0.039062  0.001215  0.016318  0.015283 -0.028674   \n",
       "441 -0.045472 -0.044642 -0.073030 -0.081413  0.083740  0.027809  0.173816   \n",
       "\n",
       "           s4        s5        s6  target  \n",
       "0   -0.002592  0.019907 -0.017646   151.0  \n",
       "1   -0.039493 -0.068332 -0.092204    75.0  \n",
       "2   -0.002592  0.002861 -0.025930   141.0  \n",
       "3    0.034309  0.022688 -0.009362   206.0  \n",
       "4   -0.002592 -0.031988 -0.046641   135.0  \n",
       "..        ...       ...       ...     ...  \n",
       "437 -0.002592  0.031193  0.007207   178.0  \n",
       "438  0.034309 -0.018114  0.044485   104.0  \n",
       "439 -0.011080 -0.046883  0.015491   132.0  \n",
       "440  0.026560  0.044529 -0.025930   220.0  \n",
       "441 -0.039493 -0.004222  0.003064    57.0  \n",
       "\n",
       "[442 rows x 11 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "8fe381e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>bmi</th>\n",
       "      <th>bp</th>\n",
       "      <th>s1</th>\n",
       "      <th>s2</th>\n",
       "      <th>s3</th>\n",
       "      <th>s4</th>\n",
       "      <th>s5</th>\n",
       "      <th>s6</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>442.000</td>\n",
       "      <td>442.000</td>\n",
       "      <td>442.000</td>\n",
       "      <td>442.000</td>\n",
       "      <td>442.000</td>\n",
       "      <td>442.000</td>\n",
       "      <td>442.000</td>\n",
       "      <td>442.000</td>\n",
       "      <td>442.000</td>\n",
       "      <td>442.000</td>\n",
       "      <td>442.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>152.133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.048</td>\n",
       "      <td>0.048</td>\n",
       "      <td>0.048</td>\n",
       "      <td>0.048</td>\n",
       "      <td>0.048</td>\n",
       "      <td>0.048</td>\n",
       "      <td>0.048</td>\n",
       "      <td>0.048</td>\n",
       "      <td>0.048</td>\n",
       "      <td>0.048</td>\n",
       "      <td>77.093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-0.107</td>\n",
       "      <td>-0.045</td>\n",
       "      <td>-0.090</td>\n",
       "      <td>-0.112</td>\n",
       "      <td>-0.127</td>\n",
       "      <td>-0.116</td>\n",
       "      <td>-0.102</td>\n",
       "      <td>-0.076</td>\n",
       "      <td>-0.126</td>\n",
       "      <td>-0.138</td>\n",
       "      <td>25.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-0.037</td>\n",
       "      <td>-0.045</td>\n",
       "      <td>-0.034</td>\n",
       "      <td>-0.037</td>\n",
       "      <td>-0.034</td>\n",
       "      <td>-0.030</td>\n",
       "      <td>-0.035</td>\n",
       "      <td>-0.039</td>\n",
       "      <td>-0.033</td>\n",
       "      <td>-0.033</td>\n",
       "      <td>87.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.005</td>\n",
       "      <td>-0.045</td>\n",
       "      <td>-0.007</td>\n",
       "      <td>-0.006</td>\n",
       "      <td>-0.004</td>\n",
       "      <td>-0.004</td>\n",
       "      <td>-0.007</td>\n",
       "      <td>-0.003</td>\n",
       "      <td>-0.002</td>\n",
       "      <td>-0.001</td>\n",
       "      <td>140.500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.038</td>\n",
       "      <td>0.051</td>\n",
       "      <td>0.031</td>\n",
       "      <td>0.036</td>\n",
       "      <td>0.028</td>\n",
       "      <td>0.030</td>\n",
       "      <td>0.029</td>\n",
       "      <td>0.034</td>\n",
       "      <td>0.032</td>\n",
       "      <td>0.028</td>\n",
       "      <td>211.500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.111</td>\n",
       "      <td>0.051</td>\n",
       "      <td>0.171</td>\n",
       "      <td>0.132</td>\n",
       "      <td>0.154</td>\n",
       "      <td>0.199</td>\n",
       "      <td>0.181</td>\n",
       "      <td>0.185</td>\n",
       "      <td>0.134</td>\n",
       "      <td>0.136</td>\n",
       "      <td>346.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           age      sex      bmi       bp       s1       s2       s3       s4  \\\n",
       "count  442.000  442.000  442.000  442.000  442.000  442.000  442.000  442.000   \n",
       "mean    -0.000    0.000   -0.000   -0.000   -0.000    0.000   -0.000   -0.000   \n",
       "std      0.048    0.048    0.048    0.048    0.048    0.048    0.048    0.048   \n",
       "min     -0.107   -0.045   -0.090   -0.112   -0.127   -0.116   -0.102   -0.076   \n",
       "25%     -0.037   -0.045   -0.034   -0.037   -0.034   -0.030   -0.035   -0.039   \n",
       "50%      0.005   -0.045   -0.007   -0.006   -0.004   -0.004   -0.007   -0.003   \n",
       "75%      0.038    0.051    0.031    0.036    0.028    0.030    0.029    0.034   \n",
       "max      0.111    0.051    0.171    0.132    0.154    0.199    0.181    0.185   \n",
       "\n",
       "            s5       s6   target  \n",
       "count  442.000  442.000  442.000  \n",
       "mean     0.000    0.000  152.133  \n",
       "std      0.048    0.048   77.093  \n",
       "min     -0.126   -0.138   25.000  \n",
       "25%     -0.033   -0.033   87.000  \n",
       "50%     -0.002   -0.001  140.500  \n",
       "75%      0.032    0.028  211.500  \n",
       "max      0.134    0.136  346.000  "
      ]
     },
     "execution_count": 269,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.round(data.frame.describe(),3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "5b3e48c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot a histogram to visualize the distribution of the \"target\" value\n",
    "plt.hist(data.frame['target'], rwidth=0.9)\n",
    "plt.title(\"Target value distribution\")\n",
    "plt.xlabel(\"target value\")\n",
    "plt.ylabel(\"#samples\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0964e70",
   "metadata": {},
   "source": [
    "### Prepare data for model training and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "73f1b21f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into 70% training and 30% testing\n",
    "# Documentation: https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html\n",
    "# Remember to set random_state to control for the randomness\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data.data, data.target, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "5172c982",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((309, 10), (133, 10))"
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check feature matrix\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a796cd9b",
   "metadata": {},
   "source": [
    "### Fit the linear regression model on the training set and evaluate model performance on the testing set \n",
    "> Documentation: https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "id": "3ca436c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.477"
      ]
     },
     "execution_count": 273,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg = LinearRegression() # check the documentation to understand the default parameters\n",
    "reg.fit(X_train, y_train)\n",
    "e_reg = reg.score(X_test, y_test)\n",
    "np.round(e_reg,3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92373e7b",
   "metadata": {},
   "source": [
    "**Interpret feature coefficients and intercept**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "9f93ce14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  29.254, -261.706,  546.3  ,  388.398, -901.96 ,  506.763,\n",
       "        121.154,  288.035,  659.269,   41.377])"
      ]
     },
     "execution_count": 274,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.round(reg.coef_,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "id": "f66d6311",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "151.008"
      ]
     },
     "execution_count": 275,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.round(reg.intercept_,3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8baf4c48",
   "metadata": {},
   "source": [
    "**[Group activity]: explore other parameters/attributes/methods**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "13242258",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'regressor'"
      ]
     },
     "execution_count": 276,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg._estimator_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "fb849a4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['age', 'sex', 'bmi', 'bp', 's1', 's2', 's3', 's4', 's5', 's6'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 277,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg.feature_names_in_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "2aa8785a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'copy_X': True, 'fit_intercept': True, 'n_jobs': None, 'positive': False}"
      ]
     },
     "execution_count": 278,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg.get_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc280db1",
   "metadata": {},
   "source": [
    "### Fit and evaluate a Ridge regression model (with the same train/test data)\n",
    "> Documentation: https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Ridge.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "id": "71a8d3a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.423"
      ]
     },
     "execution_count": 279,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rg_reg = Ridge()\n",
    "rg_reg.fit(X_train, y_train)\n",
    "rg_reg_score = rg_reg.score(X_test, y_test)\n",
    "np.round(rg_reg_score,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "id": "3c783ca4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  45.054,  -71.947,  280.716,  195.213,   -2.229,  -17.541,\n",
       "       -148.689,  120.467,  198.614,  106.935])"
      ]
     },
     "execution_count": 280,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.round(rg_reg.coef_,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "id": "a4deaa4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "151.867"
      ]
     },
     "execution_count": 281,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.round(rg_reg.intercept_,3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39b58d2f",
   "metadata": {},
   "source": [
    "### Fit and evaluate a Lasso regression model (with the same train/test data)\n",
    "> Documentation: https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Lasso.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "id": "1c416398",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.362"
      ]
     },
     "execution_count": 282,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ls_reg = Lasso()\n",
    "ls_reg.fit(X_train, y_train)\n",
    "ls_reg_score = ls_reg.score(X_test, y_test)\n",
    "np.round(ls_reg_score, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27798d1e",
   "metadata": {},
   "source": [
    "**Interpret feature coefficients and intercept**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "id": "2c5dea51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0.   ,  -0.   , 443.703,  51.601,   0.   ,   0.   ,  -0.   ,\n",
       "         0.   , 201.966,   0.   ])"
      ]
     },
     "execution_count": 283,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.round(ls_reg.coef_, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "id": "4fbdf626",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "152.166"
      ]
     },
     "execution_count": 284,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.round(ls_reg.intercept_, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c950962e",
   "metadata": {},
   "source": [
    "### Compare the linear/ridge/lasso regression models\n",
    "- write your own code to generate the following dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "id": "731cc0b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>linear</th>\n",
       "      <th>ridge</th>\n",
       "      <th>lasso</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>age</th>\n",
       "      <td>29.254</td>\n",
       "      <td>45.054</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sex</th>\n",
       "      <td>-261.706</td>\n",
       "      <td>-71.947</td>\n",
       "      <td>-0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bmi</th>\n",
       "      <td>546.300</td>\n",
       "      <td>280.716</td>\n",
       "      <td>443.703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bp</th>\n",
       "      <td>388.398</td>\n",
       "      <td>195.213</td>\n",
       "      <td>51.601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>s1</th>\n",
       "      <td>-901.960</td>\n",
       "      <td>-2.229</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>s2</th>\n",
       "      <td>506.763</td>\n",
       "      <td>-17.541</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>s3</th>\n",
       "      <td>121.154</td>\n",
       "      <td>-148.689</td>\n",
       "      <td>-0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>s4</th>\n",
       "      <td>288.035</td>\n",
       "      <td>120.467</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>s5</th>\n",
       "      <td>659.269</td>\n",
       "      <td>198.614</td>\n",
       "      <td>201.966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>s6</th>\n",
       "      <td>41.377</td>\n",
       "      <td>106.935</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      linear    ridge    lasso\n",
       "age   29.254   45.054    0.000\n",
       "sex -261.706  -71.947   -0.000\n",
       "bmi  546.300  280.716  443.703\n",
       "bp   388.398  195.213   51.601\n",
       "s1  -901.960   -2.229    0.000\n",
       "s2   506.763  -17.541    0.000\n",
       "s3   121.154 -148.689   -0.000\n",
       "s4   288.035  120.467    0.000\n",
       "s5   659.269  198.614  201.966\n",
       "s6    41.377  106.935    0.000"
      ]
     },
     "execution_count": 285,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# hint: the following dataframe shows the expected way to organize and display the information\n",
    "# make sure you round to 3 digits after the decimal point\n",
    "# make sure to rename the column names, and include intercept and score in the last two rows\n",
    "\n",
    "pd.DataFrame({'linear': np.round(reg.coef_, 3), 'ridge': np.round(\n",
    "    rg_reg.coef_, 3), 'lasso': np.round(ls_reg.coef_, 3)}, index = reg.feature_names_in_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2d7e638",
   "metadata": {},
   "source": [
    "**Your observations and thoughts of comparing the three models**\n",
    "- hint: connect this with what we discussed in the lectures, e.g.\n",
    "    - how does regularization affect coefficients and model performance \n",
    "    - what is the difference between ridge (L2 penalty) and Lasso (L1 penalty) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cae63a8b",
   "metadata": {},
   "source": [
    "- Parameters in regularized models are relatively small, which could efficiently avoid over sensitivity to training data and prevent overfitting. However, the model performance will decrease after conducting regularization, because how well the model fits will sacrifice when the complexity of the model is reduces.\n",
    "- Regarding the difference between ridge and lasso, there's a lot of coefficients are reduced to zero after l1 regularization. This is because lasso regularization takes charge of feature selection while ridge penalize the large coefficients within a reasonable level but never reduce any of them to zero."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cca80a6",
   "metadata": {},
   "source": [
    "## Polynomial regression\n",
    "- Use the diabetes data with the same train and test set to fit several **Polynomial regression** models "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61aaa8fc",
   "metadata": {},
   "source": [
    "### Fit a polynomail regression model with degree=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "id": "5c660e65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(309, 66)"
      ]
     },
     "execution_count": 286,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# generate the new polynomial feature matrix for the training data \n",
    "# \"fit_transform\" on the original training feature matrix\n",
    "# reference: https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.PolynomialFeatures.html\n",
    "poly2 = PolynomialFeatures(2)\n",
    "X_train_poly2 = poly2.fit_transform(X_train)\n",
    "X_train_poly2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "id": "da88debb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(133, 66)"
      ]
     },
     "execution_count": 287,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# generate the new polynomial feature matrix for the testing data \n",
    "# only do \"transform\" on the original testing feature matrix\n",
    "# think about why do you do \"fit_transform\" on training data but only do \"transform\" on testing data?\n",
    "X_test_poly2 = poly2.transform(X_test)\n",
    "X_test_poly2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "id": "de488def",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.413"
      ]
     },
     "execution_count": 288,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit a regression model with the newly generated polynomial feature matrix \n",
    "# evaluate model performance \n",
    "poly2_reg = LinearRegression()\n",
    "poly2_reg.fit(X_train_poly2, y_train)\n",
    "poly2_score = poly2_reg.score(X_test_poly2, y_test)\n",
    "np.round(poly2_score,3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72079596",
   "metadata": {},
   "source": [
    "### Fit a polynomail regression model with degree=1\n",
    "- Follow the previous steps of fitting a polynomial regression model with degree=2 to **fit a new model with degree=1** (name it as $poly1\\_reg$)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "id": "e53f151c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(309, 11)"
      ]
     },
     "execution_count": 289,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "poly1 = PolynomialFeatures(1)\n",
    "X_train_poly1 = poly1.fit_transform(X_train)\n",
    "X_train_poly1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "id": "794b0562",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(133, 11)"
      ]
     },
     "execution_count": 290,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_poly1 = poly1.fit_transform(X_test)\n",
    "X_test_poly1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "id": "c54df601",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.48"
      ]
     },
     "execution_count": 291,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "poly1_reg = LinearRegression()\n",
    "poly1_reg.fit(X_train_poly1, y_train)\n",
    "poly1_score = poly1_reg.score(X_test_poly1, y_test)\n",
    "np.round(poly1_score,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae2b9642",
   "metadata": {},
   "source": [
    "### Fit a polynomail regression model with degree=3\n",
    "- Follow the previous steps of fitting a polynomial regression model with degree=2 to **fit a new model with degree=3** (name it as $poly3\\_reg$)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "id": "8760be74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(309, 286)"
      ]
     },
     "execution_count": 292,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "poly3 = PolynomialFeatures(3)\n",
    "X_train_poly3 = poly3.fit_transform(X_train)\n",
    "X_train_poly3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "id": "8c0b9490",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(133, 286)"
      ]
     },
     "execution_count": 293,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_poly3 = poly3.fit_transform(X_test)\n",
    "X_test_poly3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "id": "d29a3915",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.362"
      ]
     },
     "execution_count": 294,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "poly3_reg = Lasso()\n",
    "poly3_reg.fit(X_train_poly3, y_train)\n",
    "poly3_score = poly3_reg.score(X_test_poly3, y_test)\n",
    "np.round(poly3_score, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efc159ab",
   "metadata": {},
   "source": [
    "### Compare the polynomial regression models with degree=1/2/3 and the original linear regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "id": "4e7a5efd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>linear</th>\n",
       "      <th>poly_d1</th>\n",
       "      <th>poly_d2</th>\n",
       "      <th>poly_d3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>intercept</th>\n",
       "      <td>151.008</td>\n",
       "      <td>151.008</td>\n",
       "      <td>-360.919</td>\n",
       "      <td>152.166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>score</th>\n",
       "      <td>0.477</td>\n",
       "      <td>0.477</td>\n",
       "      <td>0.413</td>\n",
       "      <td>0.362</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            linear  poly_d1  poly_d2  poly_d3\n",
       "intercept  151.008  151.008 -360.919  152.166\n",
       "score        0.477    0.477    0.413    0.362"
      ]
     },
     "execution_count": 295,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame({'linear': np.round((reg.intercept_, e_reg), 3),\n",
    "             'poly_d1': np.round((poly1_reg.intercept_, poly1_score), 3), \n",
    "             'poly_d2': np.round((poly2_reg.intercept_, poly2_score), 3), \n",
    "             'poly_d3': np.round((poly3_reg.intercept_, poly3_score), 3)},\n",
    "             index=['intercept', 'score'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "051b17b2",
   "metadata": {},
   "source": [
    "### Your observations and thoughts of comparing the above four models\n",
    "- hint: connect this with overfitting/underfitting we discussed in class"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5a65f9e",
   "metadata": {},
   "source": [
    "- Firstly, the intercepts and scores of linear model amd polynomial model with degree=1 are the same, because they are actually the same model. \n",
    "- Secondly, when we raise the degree to 2, the model is more complex and captures more information from the training data, which could result in overfitting. That is why the score of poly_d2 is lower than poly_d1, indicating that the model learns the noise of training data and can not fit the testing data very well.\n",
    "- When it comes to degree=3, the intercept is normal but the score is lower. The overfitting problem is more serious here than in the degree=2 model. It approximates the true function almost perfectly, which leads to low training error but drastically high testing/generalization error."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e005bd8",
   "metadata": {},
   "source": [
    "### Interpret the model performance wrt the task itself\n",
    "- how does each feature relate with diabetes\n",
    "- which factors contribute most to diabetes\n",
    "- does these statistical correlations make sense from biological perspective? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "id": "56641a54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>poly_d1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>s5</th>\n",
       "      <td>659.269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bmi</th>\n",
       "      <td>546.300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>s2</th>\n",
       "      <td>506.763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bp</th>\n",
       "      <td>388.398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>s4</th>\n",
       "      <td>288.035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>s3</th>\n",
       "      <td>121.154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>s6</th>\n",
       "      <td>41.377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>age</th>\n",
       "      <td>29.254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sex</th>\n",
       "      <td>-261.706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>s1</th>\n",
       "      <td>-901.960</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     poly_d1\n",
       "s5   659.269\n",
       "bmi  546.300\n",
       "s2   506.763\n",
       "bp   388.398\n",
       "s4   288.035\n",
       "s3   121.154\n",
       "s6    41.377\n",
       "age   29.254\n",
       "sex -261.706\n",
       "s1  -901.960"
      ]
     },
     "execution_count": 296,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = pd.DataFrame({'poly_d1': np.round(\n",
    "    poly1_reg.coef_, 3)[1:]}, index=poly1.feature_names_in_)\n",
    "df1_sorted = df1.sort_values(by='poly_d1', ascending=False)\n",
    "df1_sorted"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "811c51fa",
   "metadata": {},
   "source": [
    "In poly_d1, possibly log of serum triglycerides level (s5) contributes the most to diabetes, followed by bm1, low-density lipoproteins (s2), and average blood pressure (bp)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "id": "54390737",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>poly_d2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>s1 s5</th>\n",
       "      <td>401069.079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>s2</th>\n",
       "      <td>100519.161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>s1 s2</th>\n",
       "      <td>100197.282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>s5^2</th>\n",
       "      <td>71613.325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>s1 s3</th>\n",
       "      <td>52228.787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>s3</th>\n",
       "      <td>42409.255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>s5</th>\n",
       "      <td>38222.786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bp s1</th>\n",
       "      <td>24643.866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sex s2</th>\n",
       "      <td>8434.088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>s4^2</th>\n",
       "      <td>8377.907</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           poly_d2\n",
       "s1 s5   401069.079\n",
       "s2      100519.161\n",
       "s1 s2   100197.282\n",
       "s5^2     71613.325\n",
       "s1 s3    52228.787\n",
       "s3       42409.255\n",
       "s5       38222.786\n",
       "bp s1    24643.866\n",
       "sex s2    8434.088\n",
       "s4^2      8377.907"
      ]
     },
     "execution_count": 297,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 = pd.DataFrame({'poly_d2': np.round(\n",
    "    poly2_reg.coef_, 3)}, index=poly2.get_feature_names_out())[1:]\n",
    "df2_sorted = df2.sort_values(by='poly_d2', ascending=False)\n",
    "df2_sorted[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c17314be",
   "metadata": {},
   "source": [
    "In poly_d2, the interaction term of s1 and s5 are most effective in predicting diabetes. This means when possibly log of serum triglycerides level are high, existence of low-density lipoproteins will increase the likelihood of having diabetes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "id": "5c93fd52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>poly_d3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>bmi</th>\n",
       "      <td>443.703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>s5</th>\n",
       "      <td>201.966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bp</th>\n",
       "      <td>51.601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>age</th>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bmi s2 s4</th>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bmi s3 s6</th>\n",
       "      <td>-0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bmi s3 s5</th>\n",
       "      <td>-0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bmi s3 s4</th>\n",
       "      <td>-0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bmi s3^2</th>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bmi s2 s6</th>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           poly_d3\n",
       "bmi        443.703\n",
       "s5         201.966\n",
       "bp          51.601\n",
       "age          0.000\n",
       "bmi s2 s4    0.000\n",
       "bmi s3 s6   -0.000\n",
       "bmi s3 s5   -0.000\n",
       "bmi s3 s4   -0.000\n",
       "bmi s3^2     0.000\n",
       "bmi s2 s6    0.000"
      ]
     },
     "execution_count": 298,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3 = pd.DataFrame({'poly_d3': np.round(\n",
    "    poly3_reg.coef_, 3)}, index=poly3.get_feature_names_out())[1:]\n",
    "df3_sorted = df3.sort_values(by='poly_d3', ascending=False)\n",
    "df3_sorted[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a111c0a",
   "metadata": {},
   "source": [
    "In poly_d3, the interaction terms are all removed from the model after leveraging lasso regularization. Bm1, possibly log of serum triglycerides level (s5), and average blood pressure (bp) takes the lead in predicting diabetes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ef82f53",
   "metadata": {},
   "source": [
    "## Linear models for classification: LogisticRegression \n",
    "In this section, we will work on a banknote authentication dataset:\n",
    "- Original data source: https://archive.ics.uci.edu/ml/datasets/banknote+authentication <br>\n",
    "\n",
    "This dataset contains n = 1372 images of genuine and forged banknote-like specimens. Each image is represented by four features extracted from Wavelet Transform tool: \n",
    "    1. variance (continuous) \n",
    "    2. skewness (continuous)\n",
    "    3. curtosis (continuous)\n",
    "    4. entropy of image (continuous)\n",
    "\n",
    "And each image has a binary label of 0/1 indicating whether the banknote is forged or genuine.\n",
    "\n",
    "We will fit several logistic regression models with different parameter settings to analyze this dataset: \n",
    "The steps include:\n",
    "1. Basic data exploration:\n",
    "    > what does the data look like (#samples, #features) <br>\n",
    "    > the feature matrix and description of each feature <br>\n",
    "    > the target values <br>\n",
    "    \n",
    "2. Prepare data for model training and testing <br>\n",
    "\n",
    "3. Fit different logistic regression models (vary by parameter settings) on the training set and evaluate model performance on the testing set <br>\n",
    "\n",
    "4. Compare and understand model performance through interpreting coefficients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "574468b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cf817f24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# please change to your file path\n",
    "df_data = pickle.load(open('/Users/apple/Desktop/MACS30100/M2/banknote_authentication_dataframe.pickle', 'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a442ec9",
   "metadata": {},
   "source": [
    "### Basic dataset exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a876742b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>variance</th>\n",
       "      <th>skewness</th>\n",
       "      <th>curtosis</th>\n",
       "      <th>entropy</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.62160</td>\n",
       "      <td>8.66610</td>\n",
       "      <td>-2.8073</td>\n",
       "      <td>-0.44699</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.54590</td>\n",
       "      <td>8.16740</td>\n",
       "      <td>-2.4586</td>\n",
       "      <td>-1.46210</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.86600</td>\n",
       "      <td>-2.63830</td>\n",
       "      <td>1.9242</td>\n",
       "      <td>0.10645</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.45660</td>\n",
       "      <td>9.52280</td>\n",
       "      <td>-4.0112</td>\n",
       "      <td>-3.59440</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.32924</td>\n",
       "      <td>-4.45520</td>\n",
       "      <td>4.5718</td>\n",
       "      <td>-0.98880</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1367</th>\n",
       "      <td>0.40614</td>\n",
       "      <td>1.34920</td>\n",
       "      <td>-1.4501</td>\n",
       "      <td>-0.55949</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1368</th>\n",
       "      <td>-1.38870</td>\n",
       "      <td>-4.87730</td>\n",
       "      <td>6.4774</td>\n",
       "      <td>0.34179</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1369</th>\n",
       "      <td>-3.75030</td>\n",
       "      <td>-13.45860</td>\n",
       "      <td>17.5932</td>\n",
       "      <td>-2.77710</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1370</th>\n",
       "      <td>-3.56370</td>\n",
       "      <td>-8.38270</td>\n",
       "      <td>12.3930</td>\n",
       "      <td>-1.28230</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1371</th>\n",
       "      <td>-2.54190</td>\n",
       "      <td>-0.65804</td>\n",
       "      <td>2.6842</td>\n",
       "      <td>1.19520</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1372 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      variance  skewness  curtosis  entropy  class\n",
       "0      3.62160   8.66610   -2.8073 -0.44699    0.0\n",
       "1      4.54590   8.16740   -2.4586 -1.46210    0.0\n",
       "2      3.86600  -2.63830    1.9242  0.10645    0.0\n",
       "3      3.45660   9.52280   -4.0112 -3.59440    0.0\n",
       "4      0.32924  -4.45520    4.5718 -0.98880    0.0\n",
       "...        ...       ...       ...      ...    ...\n",
       "1367   0.40614   1.34920   -1.4501 -0.55949    1.0\n",
       "1368  -1.38870  -4.87730    6.4774  0.34179    1.0\n",
       "1369  -3.75030 -13.45860   17.5932 -2.77710    1.0\n",
       "1370  -3.56370  -8.38270   12.3930 -1.28230    1.0\n",
       "1371  -2.54190  -0.65804    2.6842  1.19520    1.0\n",
       "\n",
       "[1372 rows x 5 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# display the dataset\n",
    "df_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "222a148c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>variance</th>\n",
       "      <th>skewness</th>\n",
       "      <th>curtosis</th>\n",
       "      <th>entropy</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1372.000000</td>\n",
       "      <td>1372.000000</td>\n",
       "      <td>1372.000000</td>\n",
       "      <td>1372.000000</td>\n",
       "      <td>1372.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.433735</td>\n",
       "      <td>1.922353</td>\n",
       "      <td>1.397627</td>\n",
       "      <td>-1.191657</td>\n",
       "      <td>0.444606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.842763</td>\n",
       "      <td>5.869047</td>\n",
       "      <td>4.310030</td>\n",
       "      <td>2.101013</td>\n",
       "      <td>0.497103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-7.042100</td>\n",
       "      <td>-13.773100</td>\n",
       "      <td>-5.286100</td>\n",
       "      <td>-8.548200</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-1.773000</td>\n",
       "      <td>-1.708200</td>\n",
       "      <td>-1.574975</td>\n",
       "      <td>-2.413450</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.496180</td>\n",
       "      <td>2.319650</td>\n",
       "      <td>0.616630</td>\n",
       "      <td>-0.586650</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2.821475</td>\n",
       "      <td>6.814625</td>\n",
       "      <td>3.179250</td>\n",
       "      <td>0.394810</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>6.824800</td>\n",
       "      <td>12.951600</td>\n",
       "      <td>17.927400</td>\n",
       "      <td>2.449500</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          variance     skewness     curtosis      entropy        class\n",
       "count  1372.000000  1372.000000  1372.000000  1372.000000  1372.000000\n",
       "mean      0.433735     1.922353     1.397627    -1.191657     0.444606\n",
       "std       2.842763     5.869047     4.310030     2.101013     0.497103\n",
       "min      -7.042100   -13.773100    -5.286100    -8.548200     0.000000\n",
       "25%      -1.773000    -1.708200    -1.574975    -2.413450     0.000000\n",
       "50%       0.496180     2.319650     0.616630    -0.586650     0.000000\n",
       "75%       2.821475     6.814625     3.179250     0.394810     1.000000\n",
       "max       6.824800    12.951600    17.927400     2.449500     1.000000"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# describe the data \n",
    "df_data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dcbafff",
   "metadata": {},
   "source": [
    "### Prepara data for model training and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1fbc714a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1372, 4), (1372,), Counter({0.0: 762, 1.0: 610}))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_names = ['variance','skewness','curtosis','entropy']\n",
    "# Construct feature matrix from the data frame\n",
    "X_data = df_data[feature_names]\n",
    "y_data = df_data['class']\n",
    "X_data.shape, y_data.shape, Counter(y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "98dc3fbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data into 70% training and 30% testing using train_test_split()\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_data, y_data, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16c5d0d1",
   "metadata": {},
   "source": [
    "### Fit LogisticRegression models with different parameter settings\n",
    "- l1 VS l2 penalty\n",
    "- C values (inverse of regularization strength)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ff46ad51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(C=0.1, max_iter=1000, penalty=&#x27;l1&#x27;, random_state=42,\n",
       "                   solver=&#x27;liblinear&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(C=0.1, max_iter=1000, penalty=&#x27;l1&#x27;, random_state=42,\n",
       "                   solver=&#x27;liblinear&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(C=0.1, max_iter=1000, penalty='l1', random_state=42,\n",
       "                   solver='liblinear')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log = LogisticRegression(penalty='l1', C=0.1, random_state=42, max_iter=1000, solver='liblinear')\n",
    "log.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9160ab01",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_c(X_train, y_train, X_test, y_test, p):\n",
    "    \"\"\"\n",
    "    X_train/test: 2D feature matrix of training/testing data\n",
    "    y_train/test: 1D array of training/testing labels\n",
    "    p: the penalty parameter setting in LogisticRegression\n",
    "    \n",
    "    return: \n",
    "        a list of classifiers fitted with different c values\n",
    "        a dataframe that is shown in the running example below\n",
    "    \"\"\"\n",
    "    classifiers = []\n",
    "    c_list = [0.001, 0.01, 0.1, 1, 10, 100]\n",
    "    min_list = []\n",
    "    max_list = []\n",
    "    mean_abs_list = []\n",
    "    n_zero_list = []\n",
    "    test_score_list = []\n",
    "\n",
    "    # set the model parameter c to different values and train the model \n",
    "    for c in c_list:\n",
    "        # fit a LogisticRegression model with: the current c value, the given penalty p, set random_state=42, max_iter=1000, solver='liblinear', and use default setting for other parameters\n",
    "        log = LogisticRegression(\n",
    "            penalty=p, C=c, random_state=42, max_iter=1000, solver='liblinear')\n",
    "        log.fit(X_train, y_train)\n",
    "\n",
    "        classifiers.append(log)\n",
    "\n",
    "        # get the statistical information about the model coefficients:\n",
    "        # min: minimum coefficient\n",
    "        # max: minimum coefficient\n",
    "        # mean(abs(coef)): average over the absolute coefficient values\n",
    "        # n_zero: number of coefficients equal to zero\n",
    "\n",
    "        min_list.append(log.coef_.min())\n",
    "        max_list.append(log.coef_.max())\n",
    "        mean_abs_list.append(np.abs(log.coef_).mean())\n",
    "        n_zero_list.append((log.coef_ == 0).sum())\n",
    "\n",
    "        # test and record the model performance \n",
    "        test_score_list.append(log.score(X_test, y_test))\n",
    "\n",
    "    df = pd.DataFrame({'c': np.round(np.array(c_list), 3),\n",
    "                       'min': np.round(np.array(min_list), 3),\n",
    "                       'max': np.round(np.array(max_list), 3),\n",
    "                       'mean_abs': np.round(np.array(mean_abs_list), 3),\n",
    "                       'n_zero': np.round(np.array(n_zero_list), 3),\n",
    "                       'test_score': np.round(np.array(test_score_list), 3)})\n",
    "    \n",
    "    return classifiers, df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d7fb1b3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>c</th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "      <th>mean_abs</th>\n",
       "      <th>n_zero</th>\n",
       "      <th>test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.001</td>\n",
       "      <td>-0.357</td>\n",
       "      <td>-0.074</td>\n",
       "      <td>0.190</td>\n",
       "      <td>0</td>\n",
       "      <td>0.922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.010</td>\n",
       "      <td>-0.861</td>\n",
       "      <td>-0.173</td>\n",
       "      <td>0.485</td>\n",
       "      <td>0</td>\n",
       "      <td>0.973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.100</td>\n",
       "      <td>-1.581</td>\n",
       "      <td>-0.163</td>\n",
       "      <td>0.915</td>\n",
       "      <td>0</td>\n",
       "      <td>0.988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.000</td>\n",
       "      <td>-2.835</td>\n",
       "      <td>-0.166</td>\n",
       "      <td>1.645</td>\n",
       "      <td>0</td>\n",
       "      <td>0.988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10.000</td>\n",
       "      <td>-5.171</td>\n",
       "      <td>-0.290</td>\n",
       "      <td>2.937</td>\n",
       "      <td>0</td>\n",
       "      <td>0.988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>100.000</td>\n",
       "      <td>-7.648</td>\n",
       "      <td>-0.438</td>\n",
       "      <td>4.297</td>\n",
       "      <td>0</td>\n",
       "      <td>0.990</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         c    min    max  mean_abs  n_zero  test_score\n",
       "0    0.001 -0.357 -0.074     0.190       0       0.922\n",
       "1    0.010 -0.861 -0.173     0.485       0       0.973\n",
       "2    0.100 -1.581 -0.163     0.915       0       0.988\n",
       "3    1.000 -2.835 -0.166     1.645       0       0.988\n",
       "4   10.000 -5.171 -0.290     2.937       0       0.988\n",
       "5  100.000 -7.648 -0.438     4.297       0       0.990"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# running example\n",
    "l2_clfs, c_effect_l2 = compare_c(X_train, y_train, X_test, y_test, p='l2')\n",
    "c_effect_l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7bd278a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>c</th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "      <th>mean_abs</th>\n",
       "      <th>n_zero</th>\n",
       "      <th>test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.001</td>\n",
       "      <td>-0.042</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.010</td>\n",
       "      <td>3</td>\n",
       "      <td>0.624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.010</td>\n",
       "      <td>-0.807</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.328</td>\n",
       "      <td>1</td>\n",
       "      <td>0.917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.100</td>\n",
       "      <td>-1.750</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.936</td>\n",
       "      <td>1</td>\n",
       "      <td>0.988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.000</td>\n",
       "      <td>-3.838</td>\n",
       "      <td>-0.132</td>\n",
       "      <td>2.164</td>\n",
       "      <td>0</td>\n",
       "      <td>0.988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10.000</td>\n",
       "      <td>-7.110</td>\n",
       "      <td>-0.389</td>\n",
       "      <td>3.993</td>\n",
       "      <td>0</td>\n",
       "      <td>0.990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>100.000</td>\n",
       "      <td>-8.196</td>\n",
       "      <td>-0.464</td>\n",
       "      <td>4.596</td>\n",
       "      <td>0</td>\n",
       "      <td>0.990</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         c    min    max  mean_abs  n_zero  test_score\n",
       "0    0.001 -0.042  0.000     0.010       3       0.624\n",
       "1    0.010 -0.807  0.000     0.328       1       0.917\n",
       "2    0.100 -1.750  0.000     0.936       1       0.988\n",
       "3    1.000 -3.838 -0.132     2.164       0       0.988\n",
       "4   10.000 -7.110 -0.389     3.993       0       0.990\n",
       "5  100.000 -8.196 -0.464     4.596       0       0.990"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# running example\n",
    "l1_clfs, c_effect_l1 = compare_c(X_train, y_train, X_test, y_test, p='l1')\n",
    "c_effect_l1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "934a8855",
   "metadata": {},
   "source": [
    "### Compare model performance with different c values and different penalties\n",
    "- hints: \n",
    "  - explain model performance from the perspective of under-fitting VS over-fitting\n",
    "  - compare the two tables and indicate the difference between L1 and L2 penalty\n",
    "  - how does c affect coefficients and model performance in each table "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18590de0",
   "metadata": {},
   "source": [
    "- Difference between L1 and L2 penalty: L1 serves feature selection, which sets the coefficient of important features as 0. In comparison, L2 penalty never reduce the coefficients to 0 though it also penalizes large weights. That is why the number of coefficients that equals zero is 0 in all the classifiers with L2 penalty, while some of the classifiers with L1 panelty (those with smaller c value) could be above 0. Compared to L1 regularization, models with L2 regularization performs relatively well on testing data (still, when c is low). This is also the consequence of penalizing the large weights but never setting them to zero, which effectly retains the complexity of the model.\n",
    "- C is the inverse of regularization strength by definition. As the regularization aims at avoid overfitting and reaching the balance between the loss of information and the model complexity, (1/C) is actually a multiplier of the complexity, where larger C indicates smaller regularization on complexity. This can explain why n_zero decreases as C increases among the L1 regularization models. With this understanding, it is also reasonable that the model performance is bad when C is small, because the model complexity is reduced too much that resulting in underfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cd39d68",
   "metadata": {},
   "source": [
    "### Interpret the model performance wrt the banknote authentication task\n",
    "- how does each feature relate with the identification of genuine and forged banknote\n",
    "- does these statistical correlations make sense from the perspective of image recognition "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "10b5371a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['variance', 'skewness', 'curtosis', 'entropy'], dtype=object)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l2_clfs[0].feature_names_in_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9effc69e",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = np.array(['variance', 'skewness', 'curtosis', 'entropy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "345a2aac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>variance</th>\n",
       "      <td>-0.357242</td>\n",
       "      <td>-0.860815</td>\n",
       "      <td>-1.580581</td>\n",
       "      <td>-2.834711</td>\n",
       "      <td>-5.171020</td>\n",
       "      <td>-7.647564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>skewness</th>\n",
       "      <td>-0.199323</td>\n",
       "      <td>-0.456351</td>\n",
       "      <td>-0.898888</td>\n",
       "      <td>-1.635998</td>\n",
       "      <td>-2.815431</td>\n",
       "      <td>-4.037581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>curtosis</th>\n",
       "      <td>-0.128064</td>\n",
       "      <td>-0.451136</td>\n",
       "      <td>-1.017881</td>\n",
       "      <td>-1.943597</td>\n",
       "      <td>-3.471813</td>\n",
       "      <td>-5.065123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>entropy</th>\n",
       "      <td>-0.074218</td>\n",
       "      <td>-0.172662</td>\n",
       "      <td>-0.162763</td>\n",
       "      <td>-0.166099</td>\n",
       "      <td>-0.289579</td>\n",
       "      <td>-0.437990</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 0         1         2         3         4         5\n",
       "variance -0.357242 -0.860815 -1.580581 -2.834711 -5.171020 -7.647564\n",
       "skewness -0.199323 -0.456351 -0.898888 -1.635998 -2.815431 -4.037581\n",
       "curtosis -0.128064 -0.451136 -1.017881 -1.943597 -3.471813 -5.065123\n",
       "entropy  -0.074218 -0.172662 -0.162763 -0.166099 -0.289579 -0.437990"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Assuming you have a list of linear models l2_clfs\n",
    "\n",
    "coef_data = []  # List to store coefficient data for each model\n",
    "for i, clf in enumerate(l2_clfs):\n",
    "    coef_data.append(clf.coef_)\n",
    "\n",
    "# Reshape the coefficient data to have the desired shape (4, 1)\n",
    "coef_data = [coef.reshape(-1, 1) for coef in coef_data]\n",
    "\n",
    "# Create a DataFrame for each model's coefficients\n",
    "coef_dfs = [pd.DataFrame(data=coef, columns=[str(i)], index=features)\n",
    "            for i, coef in enumerate(coef_data)]\n",
    "\n",
    "# Concatenate the DataFrames along columns to create the final DataFrame\n",
    "pd.concat(coef_dfs, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8d048ac4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>variance</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.807180</td>\n",
       "      <td>-1.750236</td>\n",
       "      <td>-3.838485</td>\n",
       "      <td>-7.109730</td>\n",
       "      <td>-8.196342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>skewness</th>\n",
       "      <td>-0.041929</td>\n",
       "      <td>-0.256116</td>\n",
       "      <td>-0.908599</td>\n",
       "      <td>-2.109574</td>\n",
       "      <td>-3.762224</td>\n",
       "      <td>-4.306553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>curtosis</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.247713</td>\n",
       "      <td>-1.084607</td>\n",
       "      <td>-2.575659</td>\n",
       "      <td>-4.710904</td>\n",
       "      <td>-5.416520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>entropy</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.132006</td>\n",
       "      <td>-0.388707</td>\n",
       "      <td>-0.463991</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 0         1         2         3         4         5\n",
       "variance  0.000000 -0.807180 -1.750236 -3.838485 -7.109730 -8.196342\n",
       "skewness -0.041929 -0.256116 -0.908599 -2.109574 -3.762224 -4.306553\n",
       "curtosis  0.000000 -0.247713 -1.084607 -2.575659 -4.710904 -5.416520\n",
       "entropy   0.000000  0.000000  0.000000 -0.132006 -0.388707 -0.463991"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Assuming you have a list of linear models l1_clfs\n",
    "\n",
    "coef_data = []  # List to store coefficient data for each model\n",
    "for i, clf in enumerate(l1_clfs):\n",
    "    coef_data.append(clf.coef_)\n",
    "\n",
    "# Reshape the coefficient data to have the desired shape (4, 1)\n",
    "coef_data = [coef.reshape(-1, 1) for coef in coef_data]\n",
    "\n",
    "# Create a DataFrame for each model's coefficients\n",
    "coef_dfs = [pd.DataFrame(data=coef, columns=[str(i)], index=features)\n",
    "            for i, coef in enumerate(coef_data)]\n",
    "\n",
    "# Concatenate the DataFrames along columns to create the final DataFrame\n",
    "pd.concat(coef_dfs, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f02dd4a",
   "metadata": {},
   "source": [
    "In the logistic models with l2 regularization, variance is the most important feature correlated with the genuine of the image. \n",
    "In the models with l1 regularization, variance is the most important feature in the last five models. The first model have penalized the large weight of it so the most prominent feature is skewness. \n",
    "Variance measures the spread or dispersion of data points in a dataset. In the context of image analysis, variance can be useful for noise detection, blur dectection, tampering detection, and quality assessment.It's important to note that while variance can be a valuable tool in image analysis and tampering detection, it is not the only factor to consider. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29bcb91b",
   "metadata": {},
   "source": [
    "## Summary\n",
    "Congratulations for completing this exercise! In this notebook, with hands-on practice of linear models for regression and classification tasks, we gain deep understanding of:\n",
    "- overfitting VS underfitting\n",
    "- difference between l1 and l2 regularizations\n",
    "- the effect of regularization strength on model performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "327df471",
   "metadata": {},
   "source": [
    "## Which part(s) you find most interesting/chanlleging?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c027608",
   "metadata": {},
   "source": [
    "I think the most important part is designing a function to fit models with different parameters and generate dataframe to compare their performance. This really improves my efficiency in finding the best model."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
